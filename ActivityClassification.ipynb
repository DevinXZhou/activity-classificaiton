{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Project: Physical Activity Monitoring</center></h1>\n",
    "<h3><div style=\"text-align: right\"> Course: Big Data Tools and Methods<br>Kernel: Apache Toree - Scala<br>Author: Xin Zhou</div></h1>\n",
    "## Introduction\n",
    "The paper of \"Introducing a New Benchmarked Dataset for Activity Monitoring\" was published in 2012, and dataset \"PAMAP2\" was downloaded from UCI Machine Learning Depository. German Research Center of Artificial Intelligence (DFKI) establised this dataset for research purpose, and they had achieved high accuracy on physical activity monitoring problems. In this project, raw data \"PAMAP2\" had been used and preprocessed using python script named \"csvConvert.py\". In order to reach the benchmarking classification accuracy in this paper, several preprocess methods had used to find the most important data attribute. The decision tree classifier was first used to test the classification accuracy, then several other classifiers were used for model comparison purpose. Some problems were showed up during experiment, and they will be discussed in this project.<br>\n",
    "\n",
    "### Dataset Subjects Information\n",
    "All data are recorded from total of 9 people subjects followed by protocols. Minimum age is 23 and maximum age is 31. From height and weight information, they are in healthy shape. More specific information are inluded in the \"PAMAP2_Dataset\" which can be downloaded at https://archive.ics.uci.edu/ml/datasets/PAMAP2+Physical+Activity+Monitoring <br>\n",
    "There are total of 54 attributes collected from each subject shown as below.\n",
    "### PAMAP2 Dataset Attribute Information\n",
    "The 54 columns in the data files are organized as follows: <br>\n",
    "1.\ttimestamp (s) <br>\n",
    "2.\tactivityID (see below for the mapping to the activities) <br>\n",
    "3.\theart rate (bpm) <br>\n",
    "4. ~ 20.\tIMU hand <br>\n",
    "21. ~ 37.\tIMU chest <br>\n",
    "38. ~ 54.\tIMU ankle <br>\n",
    "\n",
    "The IMU sensory data contains the following columns: <br>\n",
    "1.\ttemperature (Â°C) <br>\n",
    "2. ~ 4.\t3D-acceleration data (ms-2), scale: Â±16g, resolution: 13-bit <br>\n",
    "5. ~ 7.\t3D-acceleration data (ms-2), scale: Â±6g, resolution: 13-bit <br>\n",
    "8. ~ 10.\t3D-gyroscope data (rad/s) <br>\n",
    "11. ~ 13.\t3D-magnetometer data (Î¼T) <br>\n",
    "14. ~ 17.\torientation (invalid in this data collection) <br>\n",
    "\n",
    "List of activityIDs and corresponding activities: <br>\n",
    "1\tlying, 2\tsitting, 3\tstanding, 4\twalking, 5\trunning, 6\tcycling, 7\tNordic walking, 9\twatching TV, 10\tcomputer work, 11\tcar driving, 12\tascending stairs, 13\tdescending stairs, 16\tvacuum cleaning, 17\tironing, 18\tfolding laundry, 19\thouse cleaning, 20\tplaying soccer, 24\trope jumping, 0\tother (transient activities)\n",
    "### Preprocessing \n",
    "#### CSV Data File Generation\n",
    "In python script \"csvConvert.py\", total of 10 .csv files are generated from 9 .dat files. One csv file named \"subjectsAll.csv\" included all 9 subjects attributes. Other 9 csv files are simplied converted from subject101.dat ~ subject109.dat files. During conversion, there are 5 extra attributes added in. Which are age, height, weight, minBPM, maxBPM. <br>\n",
    "#### Drop Useless Attributes\n",
    "Atribute in column of 17, 18, 19, 20 are always the same as data of [1, 0, 0, 0]. So are the column 34, 35, 36, 37 and column 51, 52, 53, 54. These 12 columns of attributes are orientations from three IMU sensors which are invalid, so they will be dropped. The column 1 attibute is time which will be dropped, because there are none models like RNN or LSTM will used for this dataset. <br>\n",
    "#### Dealing with NULL in Attribute of Heart Beats (bpm)\n",
    "From observation in the dataset, many \"null\" are recorded in the heart beats attribute. Several methods had been tested as shown below. <br>\n",
    "1 Average all attributes in a time window. In such window, only one row has valid bpm data.<br>\n",
    "2 Drop hearts beats attribute \"bpm\"<br>\n",
    "3 Drop only rows with \"null\", and keep the rows which contain valid bpm <br><br>\n",
    "As an experiment result in option 1, apache toree scala does not inference double type data from csv file which contains all averaged data. Using specified Struct would generate null, so such option 1 was given up. <br>\n",
    "Option 2 gives a low accuracy such as 87% in basic activity classification, but option 3 gives 99.9% which means bpm is a very import attribute in this data set. <br>\n",
    "\n",
    "### Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Author: Xin Zhou\n",
    "// Setup training files and decision tree model parameters\n",
    "// subjectNumber can be int chosen from 101 to 109, can also be string \"All\" which will extract all subjects data\n",
    "// activityMin and activityMax are specifying the range of activity ID\n",
    "// Basic Activity, activityMin = 1, activityMax = 5\n",
    "// Background Activity, activityMin = 6, activityMax = 12\n",
    "// All acitivity in the paper means first 12 activity, activityMin = 1, activityMax = 12\n",
    "val subjectNumber = \"All\"\n",
    "val activityMin = 1\n",
    "val activityMax = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+--------------------+\n",
      "|predictedLabel|label|            features|\n",
      "+--------------+-----+--------------------+\n",
      "|             1|    1|[78.0,31.4375,3.6...|\n",
      "|             1|    1|[78.0,31.4375,3.6...|\n",
      "|             1|    1|[78.0,31.4375,3.6...|\n",
      "|             1|    1|[78.0,31.4375,3.7...|\n",
      "|             1|    1|[78.0,31.4375,3.7...|\n",
      "+--------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Decision Tree Test Accuracy = 0.9372873713981227\n",
      "Test Error = 0.06271262860187732\n",
      "Decision Tree Training Elapsed time: 40s\n"
     ]
    }
   ],
   "source": [
    "//Author: Xin Zhou\n",
    "val dir = new java.io.File(\".\").getCanonicalPath\n",
    "val rawDF = spark.read.format(\"csv\").option(\"inferSchema\",true).option(\"header\",true).load(dir+\"/data/subject\"+subjectNumber.toString+\".csv\")\n",
    "// val df = spark.read.format(\"csv\").schema(schema).option(\"header\",false).load(dir+\"/data/subject101.csv\")\n",
    "val dropDF = rawDF.na.drop(\"any\").drop(\"o0\", \"o1\", \"o2\", \"o3\", \"o4\", \"o5\", \"o6\", \"o7\", \"o8\", \"o9\",\n",
    "                                  \"o10\", \"o11\", \"time\")\n",
    "val df = dropDF.filter(dropDF(\"label\") <= activityMax).filter(dropDF(\"label\") >= activityMin)\n",
    "// df.show(1)\n",
    "// df.printSchema\n",
    "import org.apache.spark.ml.feature.RFormula\n",
    "\n",
    "// add extra subject information here in formula\n",
    "// age+height+weight+minBPM+maxBPM+\n",
    "val formula = new RFormula().setFormula(\"label ~ bpm+h0+h1+h2+h3+h4+h5+h6+h7+h8+h9+h10+h11+h12+c0+c1+c2+c3+c4+c5+c6+c7+c8+c9+c10+c11+c12+a0+a1+a2+a3+a4+a5+a6+a7+a8+a9+a10+a11+a12\")\n",
    "val preparedDF = formula.fit(df).transform(df)\n",
    "\n",
    "val Array(trainingData, testData) = preparedDF.randomSplit(Array(0.7, 0.3))\n",
    "\n",
    "//train a decision tree model\n",
    "//Code below original from Spark 2.2.0 Documentation\n",
    "//https://spark.apache.org/docs/2.2.0/ml-classification-regression.html\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.classification.DecisionTreeClassificationModel\n",
    "import org.apache.spark.ml.classification.DecisionTreeClassifier\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n",
    "\n",
    "//training start time:\n",
    "val t0 = System.currentTimeMillis()\n",
    "\n",
    "val labelIndexer = new StringIndexer().setInputCol(\"label\").setOutputCol(\"indexedLabel\").fit(preparedDF)\n",
    "val featureIndexer = new VectorIndexer().setInputCol(\"features\").setOutputCol(\"indexedFeatures\").setMaxCategories(activityMax+1-activityMin).fit(preparedDF)\n",
    "\n",
    "val dt = new DecisionTreeClassifier().setLabelCol(\"indexedLabel\").setFeaturesCol(\"indexedFeatures\")\n",
    "\n",
    "val labelConverter = new IndexToString().setInputCol(\"prediction\").setOutputCol(\"predictedLabel\").setLabels(labelIndexer.labels)\n",
    "\n",
    "val pipeline = new Pipeline().setStages(Array(labelIndexer, featureIndexer, dt, labelConverter))\n",
    "\n",
    "val model = pipeline.fit(trainingData)\n",
    "\n",
    "//training end time:\n",
    "val t1 = System.currentTimeMillis()\n",
    "\n",
    "//evaluate\n",
    "val predictions = model.transform(testData)\n",
    "\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "\n",
    "val evaluator = new MulticlassClassificationEvaluator().setLabelCol(\"indexedLabel\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val accuracy = evaluator.evaluate(predictions)\n",
    "println(\"Decision Tree Test Accuracy = \" + accuracy)\n",
    "println(\"Test Error = \" + (1.0 - accuracy))\n",
    "println(\"Decision Tree Training Elapsed time: \" + (t1 - t0)/1000 + \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classification without Subjects Information\n",
    "12 Activities includes:1 lying, 2 sitting, 3 standing, 4 walking, 5 running, 6\tcycling, 7\tNordic walking, 9\twatching TV, 10\tcomputer work, 11\tcar driving, 12\tascending stairs <br>\n",
    "If include label of 0 as \"others of transient activities\" would lower such classification 12% accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | Basic Activity | Background Activity | 12 Activities | 24 Activities |\n",
    "|--- |---|---|---|\n",
    "|Subject 101| 99.99% | 100% | 99.49% | 85.78% |\n",
    "|Subject 102| 99.53% | 100% | 98.34% | 92.55% |\n",
    "|Subject 103| 99.96% | 100% | 100%   | 92.99% |\n",
    "|Subject 104| 99.47% | 100% | 99.95% | 93.29% |\n",
    "|Subject 105| 99.02% | \n",
    "|Subject 106| 99.96% |\n",
    "|Subject 107| 100%   | \n",
    "|Subject 108| 99.62% | \n",
    "|Subject 109| No Basic Activity |\n",
    "|All Subjects|94.50% |94.04%| 73.45% | 64.02% |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment: \n",
    "100% background activity accuracy is suspicious. Then it was unnecessary to test all data. In the paper, the author says \"all activities\" are all 12 activities. However, he did not say which 12. There are total of 24 activities in this dataset. Moreover, the author says \"the background activity is the other 6 of the 12 activities\". Still background activities labels are unclear. Comparing his \"All activity\" with my \"12 activities\" or compare the background activity accuracy is not reasonable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classification with Subjects Information\n",
    "Added age, weight, height, resting bpm, max bpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | Basic Activity | Background Activity | 12 Activities | 24 Activities |\n",
    "|--- |---|---|---|\n",
    "|Subject 101| 99.99% | 100% | 99.63% | 85.31% |\n",
    "|Subject 102| 99.53% | 100% | 98.34% | 81.35% |\n",
    "|All Subjects|94.14% |94.34%| 72.80% | 63.90% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment:\n",
    "12 experiments as shown above, standard subject dependent classification has almost 100% accuracy, but has only 94% accuracy classification on all subjects. The classifier for classifying basic activity and background activity has very good performance, except first 12 activities and all activities. Then the classification on basic activity with all subjects data will be used in other classifiers. As comparing these accuracies with the ones without subjects information, there are no difference or improvement on classificaition accuracy.\n",
    "<br><br>\n",
    "### Comparing to Paper Reiss2012b using Decision Tree Classifier\n",
    "Standard accuracy are using averaged accuracy on 8 subjects test accuracies. LOSO (leave-one-subject-out) is using accuracy from \"All subjects\", which model was trained from all subjects. As a test comparison result, my result is very close to the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | Standard Basic Activity Accuracy | LOSO Basic Activity Accuracy |\n",
    "|--- |---|---|\n",
    "|Reiss2012| 99.70% | 94.47% | \n",
    "|Mine| 99.69% | 94.50% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Classifiers on Apache Toree - Scala\n",
    "1. Gradient-boosted tree, invalid on this dataset which it only support binary classfication\n",
    "2. Naive Bayes, invalid for computing negative values\n",
    "3. LSVM, not a good classifier for computing this nonlinear dataset\n",
    "4. Random Forest, works slightly better than decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Original from Spark 2.2.0 Documentation\n",
    "//https://spark.apache.org/docs/2.2.0/ml-classification-regression.html\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n",
    "\n",
    "// using the same preparedDF in code block 2\n",
    "//training starts\n",
    "val t0 = System.currentTimeMillis()\n",
    "\n",
    "val labelIndexer = new StringIndexer().setInputCol(\"label\").setOutputCol(\"indexedLabel\").fit(preparedDF)\n",
    "// Automatically identify categorical features, and index them.\n",
    "// Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "val featureIndexer = new VectorIndexer().setInputCol(\"features\").setOutputCol(\"indexedFeatures\").setMaxCategories(activityMax+1-activityMin).fit(preparedDF)\n",
    "\n",
    "// Split the data into training and test sets (30% held out for testing).\n",
    "//val Array(trainingData, testData) = preparedDF.randomSplit(Array(0.7, 0.3))\n",
    "\n",
    "// Train a RandomForest model.\n",
    "val rf = new RandomForestClassifier().setLabelCol(\"indexedLabel\").setFeaturesCol(\"indexedFeatures\").setNumTrees(10)\n",
    "\n",
    "// Convert indexed labels back to original labels.\n",
    "val labelConverter = new IndexToString().setInputCol(\"prediction\").setOutputCol(\"predictedLabel\").setLabels(labelIndexer.labels)\n",
    "\n",
    "// Chain indexers and forest in a Pipeline.\n",
    "val pipeline = new Pipeline().setStages(Array(labelIndexer, featureIndexer, rf, labelConverter))\n",
    "\n",
    "// Train model. This also runs the indexers.\n",
    "val model = pipeline.fit(trainingData)\n",
    "\n",
    "//training ends\n",
    "val t1 = System.currentTimeMillis()\n",
    "\n",
    "// Make predictions.\n",
    "val predictions = model.transform(testData)\n",
    "\n",
    "// Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "\n",
    "// Select (prediction, true label) and compute test error.\n",
    "val evaluator = new MulticlassClassificationEvaluator().setLabelCol(\"indexedLabel\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val accuracy = evaluator.evaluate(predictions)\n",
    "println(\"Random Forest Test Accuracy = \" + accuracy)\n",
    "println(\"Random Forest Training Elapsed time: \" + (t1 - t0)/1000 + \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Performance Comparison\n",
    "The below table data are ranges from minum to maximum recorded in different validation run. As a result, Decision Tree and Random Forest have almost the same performance with same run time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | LOSO Basic Activity Accuracy | Training Time (s) |\n",
    "|--- |---|---|\n",
    "|Decision Tree| 93.72%~94.50% | 39~45 | \n",
    "|Random Forest| 93.98%~95.42% | 40~45 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Many classifiers had been tested on this \"PAMAP2\" dataset, such as Decision Tree, Random Forest, Naive Bayes and so  on. Only two classifiers Decision Tree and Random Forest are workable for this dataset on this Apache Toree - Scala kernel. Even though sometimes some type of classifiers work better on specific dataset, the classifier types on this \"PAMAP2\" dataset does not have apparent classfication accuracy. As an experiment result, preprocessing the raw data is the key to reach the benchmark accuracy in 2012 paper of \"Introducing a New Benchmarked Dataset for Activity Monitoring\". Another observation from experiment is that heart beats attribute plays a big role on such on physical activity classficaion problem. However, other problems were shown up. For example, a person's activities always inlude transient activities. If we do not include label of \"0\" (transient activities) in the test dataset, we have a really high accuracy for sure. However, if we put transient activities in the test dateset, the classifiers would not have a good performance classifying transient activities. If person is doing transient activities in real time, such classifier would not a good performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
